{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335cc1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garrett/miniforge3/envs/jupyter/lib/python3.8/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.4.0) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n",
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/garrett361/chat_with_determined\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://garrett361/chat_with_determined loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " \r",
      "\r",
      " \r",
      "Deep Lake Dataset in hub://garrett361/chat_with_determined already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset(path='hub://garrett361/chat_with_determined', read_only=True, tensors=['embedding', 'ids', 'metadata', 'text'])\n",
      "\n",
      "  tensor     htype       shape       dtype  compression\n",
      "  -------   -------     -------     -------  ------- \n",
      " embedding  generic  (29406, 1536)  float32   None   \n",
      "    ids      text     (29406, 1)      str     None   \n",
      " metadata    json     (29406, 1)      str     None   \n",
      "   text      text     (29406, 1)      str     None   \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import queue\n",
    "import threading\n",
    "from pprint import pprint\n",
    "\n",
    "import openai\n",
    "import streamlit as st\n",
    "import tiktoken\n",
    "from defaults import MODEL, GITHUB_BASE_URL, ROOT_DIR\n",
    "from dotenv import load_dotenv\n",
    "from langchain.callbacks.base import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain.vectorstores import DeepLake\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "\n",
    "# Load environment variables from a .env file (containing OPENAI_API_KEY)\n",
    "load_dotenv()\n",
    "# Set the OpenAI API key from the environment variable\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "active_loop_data_set_path = os.environ.get(\"DEEPLAKE_DATASET_PATH\")\n",
    "\n",
    "DB = DeepLake(\n",
    "    dataset_path=active_loop_data_set_path,\n",
    "    read_only=True,\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    ")\n",
    "encoding = tiktoken.encoding_for_model(MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4daf2",
   "metadata": {},
   "source": [
    "# Chunking Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46cc9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(root_dir, github_base_url=None, splitter=None):\n",
    "    docs = []\n",
    "    for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "        for file in filenames:\n",
    "            if file.split(\".\")[-1] not in (\n",
    "                \"png\",\n",
    "                \"jpg\",\n",
    "                \"ico\",\n",
    "                \"svg\",\n",
    "                \"bin\",\n",
    "                \"woff2\",\n",
    "                \"woff\",\n",
    "                \"h5\",\n",
    "                \"pkl\",\n",
    "                \"path\",\n",
    "                \"index\",\n",
    "                \"ttf\",\n",
    "                \"gif\",\n",
    "                \"jpeg\",\n",
    "                \"otf\",\n",
    "                \"zip\",\n",
    "                \"idx\",\n",
    "                \"pt\",\n",
    "                \"pth\",\n",
    "                \"meta\",\n",
    "                \"eot\",\n",
    "                \"map\",\n",
    "            ):\n",
    "                try:\n",
    "                    path = os.path.join(dirpath, file)\n",
    "                    loader = TextLoader(path, encoding=\"utf-8\")\n",
    "                    split_docs = loader.load_and_split(splitter)\n",
    "                    if github_base_url is not None:\n",
    "                        for doc in split_docs:\n",
    "                            doc.metadata[\"url\"] = (\n",
    "                                github_base_url + path[len(root_dir) :]\n",
    "                            )\n",
    "                    docs.extend(split_docs)\n",
    "                except Exception as e:\n",
    "                    print(\n",
    "                        f\"Exception {e} raised for file {file} but ignored; continuing.\"\n",
    "                    )\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07495a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte raised for file determined-keras-model but ignored; continuing.\n",
      "Exception 'utf-8' codec can't decode byte 0x86 in position 3: invalid start byte raised for file saved_model.pb but ignored; continuing.\n",
      "Exception 'utf-8' codec can't decode byte 0x86 in position 3: invalid start byte raised for file saved_model.pb but ignored; continuing.\n",
      "Exception 'utf-8' codec can't decode byte 0xb7 in position 1: invalid start byte raised for file determined-keras-model-weights.data-00000-of-00001 but ignored; continuing.\n",
      "Exception 'utf-8' codec can't decode byte 0x83 in position 18: invalid start byte raised for file determined-keras-model-weights.data-00000-of-00001 but ignored; continuing.\n",
      "Exception 'utf-8' codec can't decode byte 0xb7 in position 1: invalid start byte raised for file determined-keras-model-weights.data-00000-of-00001 but ignored; continuing.\n",
      "Exception 'utf-8' codec can't decode byte 0xfd in position 10: invalid start byte raised for file pack-4dc15fca96f1bb4b4e9c1b9db54e82a670084a65.pack but ignored; continuing.\n"
     ]
    }
   ],
   "source": [
    "docs = load_docs(\n",
    "    ROOT_DIR,\n",
    "    GITHUB_BASE_URL,\n",
    "    RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a6d88ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document(page_content='self.clip_grads_fn = None\\n        if self.cfg.optimizer_config.grad_clip is not None:\\n            self.clip_grads_fn = lambda x: torch.nn.utils.clip_grad_norm_(\\n                x,\\n                self.cfg.optimizer_config.grad_clip.max_norm,\\n                self.cfg.optimizer_config.grad_clip.norm_type,\\n            )\\n\\n        # mmdet sets loggers in the package that interrupt with Determined logging.\\n        # We reset the root logger after mmdet models are initialized.\\n        set_logger(bool(self.context.get_experiment_config().get(\"debug\", False)))\\n\\n    def build_mmdet_config(self) -> mmcv.Config:\\n        \"\"\"\\n        Apply overrides to the mmdet config according to the following experiment config fields:\\n        - data.file_client_args\\n        - hyperparameters.merge_config\\n        - hyperparameters.override_mmdet_config.', metadata={'source': 'determined/model_hub/model_hub/mmdetection/_trial.py', 'url': 'https://github.com/determined-ai/determined/blob/main/model_hub/model_hub/mmdetection/_trial.py'})\n"
     ]
    }
   ],
   "source": [
    "pprint(docs[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "602e2f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29406"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576edcb2",
   "metadata": {},
   "source": [
    "Uploading vectorized docs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e82cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = OpenAIEmbeddings()\n",
    "# deep_lake_path = os.environ.get(\"DEEPLAKE_DATASET_PATH\")\n",
    "# db = DeepLake(dataset_path=deep_lake_path, embedding_function=embeddings)\n",
    "# db.add_documents(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ac1cd9",
   "metadata": {},
   "source": [
    "# Vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd6b579",
   "metadata": {},
   "source": [
    "The `DB` object is the vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64a444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='def report_completed(self, searcher_metric: Any) -> None:\\n        \"\"\"\\n        ``report_completed()`` is the final step of a train-validate-report cycle.', metadata={'source': 'determined/harness/determined/core/_searcher.py', 'url': 'https://github.com/determined-ai/determined/blob/main/harness/determined/core/_searcher.py'}),\n",
      " Document(page_content='``report_completed()`` requires the value of the metric you are searching over.  This value\\n        is typically the output of the \"validate\" step of the train-validate-report cycle.\\n        In most cases `searcher_metric` should be a `float` but custom search methods\\n        may use any json-serializable type as searcher metric.\\n        \"\"\"\\n        if not self._is_chief:\\n            raise RuntimeError(\"you must only call op.report_completed() from the chief worker\")\\n        if self._completed:\\n            raise RuntimeError(\"you may only call op.report_completed() once\")\\n        self._completed = True\\n        body = {\"op\": {\"length\": self._length}, \"searcherMetric\": searcher_metric}\\n        logger.debug(f\"op.report_completed({searcher_metric})\")\\n        self._session.post(\\n            f\"/api/v1/trials/{self._trial_id}/searcher/completed_operation\",\\n            data=det.util.json_encode(body),\\n        )', metadata={'source': 'determined/harness/determined/core/_searcher.py', 'url': 'https://github.com/determined-ai/determined/blob/main/harness/determined/core/_searcher.py'}),\n",
      " Document(page_content='pex.rank != 0, RuntimeError, match=\"op.report_completed.*chief\"\\n                ):\\n                    op.report_completed(0.0)', metadata={'source': 'determined/harness/tests/core/test_searcher.py', 'url': 'https://github.com/determined-ai/determined/blob/main/harness/tests/core/test_searcher.py'}),\n",
      " Document(page_content='After training to the point specified by each ``SearcherOperation``, the chief, and only the\\n        chief, must call ``op.report_completed(``) on each operation.  This is true regardless of\\n        the ``searcher_mode`` setting because the Determined master needs a clear, unambiguous\\n        report of when an operation is completed.\\n        \"\"\"\\n        searcher_mode = SearcherMode(searcher_mode)', metadata={'source': 'determined/harness/determined/core/_searcher.py', 'url': 'https://github.com/determined-ai/determined/blob/main/harness/determined/core/_searcher.py'})]\n"
     ]
    }
   ],
   "source": [
    "pprint(DB.similarity_search(\"what does `report_completed` do?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b548924",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a036f9",
   "metadata": {},
   "source": [
    "Step 1: get the relevant docs for the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa161e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What does `report_validation_metrics` do? What is the signature of this '\n",
      " 'method?  Can I call `report_validation_metrics` twice on the same step?')\n"
     ]
    }
   ],
   "source": [
    "query = \"What does `report_validation_metrics` do? What is the signature of this method?  Can I call `report_validation_metrics` twice on the same step?\"\n",
    "pprint(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7b1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_from_query(query: str, k: int = 5) -> str:\n",
    "    docs = DB.similarity_search(query, k)\n",
    "\n",
    "    context = \"\\n\\n\".join(\n",
    "        [\n",
    "            f'From file {d.metadata[\"source\"]} (github url {d.metadata[\"url\"]}):\\n'\n",
    "            + str(d.page_content)\n",
    "            for d in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68525fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('From file determined/docs/training/apis-howto/api-core-ug.rst (github url '\n",
      " 'https://github.com/determined-ai/determined/blob/main/docs/training/apis-howto/api-core-ug.rst):\\n'\n",
      " '.. literalinclude:: ../../../examples/tutorials/core_api/1_metrics.py\\n'\n",
      " '      :language: python\\n'\n",
      " '      :pyobject: main\\n'\n",
      " '\\n'\n",
      " '   The ``report_validation_metrics()`` call typically happens after the '\n",
      " 'validation step, however,\\n'\n",
      " '   actual validation is not demonstrated by this example.\\n'\n",
      " '\\n'\n",
      " '#. Create a ``1_metrics.yaml`` file with an ``entrypoint`` invoking the new '\n",
      " '``1_metrics.py`` file.\\n'\n",
      " '   You can copy the ``0_start.yaml`` configuration file and change the first '\n",
      " 'couple of lines:\\n'\n",
      " '\\n'\n",
      " '   .. literalinclude:: ../../../examples/tutorials/core_api/1_metrics.yaml\\n'\n",
      " '      :language: yaml\\n'\n",
      " '      :lines: 1-2\\n'\n",
      " '\\n'\n",
      " '#. Run the code using the command:\\n'\n",
      " '\\n'\n",
      " '   .. code:: bash\\n'\n",
      " '\\n'\n",
      " '      det e create 1_metrics.yaml . -f\\n'\n",
      " '\\n'\n",
      " '#. You can now navigate to the new experiment in the WebUI and view the plot '\n",
      " 'populated with the\\n'\n",
      " '   training and validation metrics.\\n'\n",
      " '\\n'\n",
      " 'From file determined/harness/determined/pytorch/_pytorch_trial.py (github '\n",
      " 'url '\n",
      " 'https://github.com/determined-ai/determined/blob/main/harness/determined/pytorch/_pytorch_trial.py):\\n'\n",
      " '# Report metrics.\\n'\n",
      " '        if self.is_chief:\\n'\n",
      " '            # Skip reporting timings if evaluate_full_dataset() was '\n",
      " 'defined.  This is far less\\n'\n",
      " \"            # common than evaluate_batch() and we can't know how the user \"\n",
      " 'processed their\\n'\n",
      " '            # validation data.\\n'\n",
      " '            if self._evaluate_batch_defined():\\n'\n",
      " '                step_duration = time.time() - step_start_time\\n'\n",
      " '                logging.info(\\n'\n",
      " '                    det.util.make_timing_log(\"validated\", step_duration, '\n",
      " 'num_inputs, num_batches)\\n'\n",
      " '                )\\n'\n",
      " '            det.pytorch._log_tb_metrics(\\n'\n",
      " '                self.context.get_tensorboard_writer(), \"val\", '\n",
      " 'self.state.batches_trained, metrics\\n'\n",
      " '            )\\n'\n",
      " '\\n'\n",
      " '            # Get best validation before reporting metrics.\\n'\n",
      " '            best_validation_before = '\n",
      " 'self.core_context.train.get_experiment_best_validation()\\n'\n",
      " '\\n'\n",
      " '            '\n",
      " 'self.core_context.train.report_validation_metrics(self.state.batches_trained, '\n",
      " 'metrics)\\n'\n",
      " '\\n'\n",
      " '        searcher_metric = None\\n'\n",
      " '\\n'\n",
      " 'From file determined/harness/determined/pytorch/_reducer.py (github url '\n",
      " 'https://github.com/determined-ai/determined/blob/main/harness/determined/pytorch/_reducer.py):\\n'\n",
      " 'return metrics\\n'\n",
      " '\\n'\n",
      " 'From file determined/harness/determined/core/_train.py (github url '\n",
      " 'https://github.com/determined-ai/determined/blob/main/harness/determined/core/_train.py):\\n'\n",
      " 'def report_training_metrics(\\n'\n",
      " '        self,\\n'\n",
      " '        steps_completed: int,\\n'\n",
      " '        metrics: Dict[str, Any],\\n'\n",
      " '        batch_metrics: Optional[List[Dict[str, Any]]] = None,\\n'\n",
      " '    ) -> None:\\n'\n",
      " '        logger.info(\\n'\n",
      " '            f\"report_training_metrics(steps_completed={steps_completed}, '\n",
      " 'metrics={metrics})\"\\n'\n",
      " '        )\\n'\n",
      " '        logger.debug(\\n'\n",
      " '            f\"report_training_metrics(steps_completed={steps_completed},\"\\n'\n",
      " '            f\" batch_metrics={batch_metrics})\"\\n'\n",
      " '        )\\n'\n",
      " '\\n'\n",
      " '    def report_validation_metrics(self, steps_completed: int, metrics: '\n",
      " 'Dict[str, Any]) -> None:\\n'\n",
      " '        serializable_metrics = self._get_serializable_metrics(metrics)\\n'\n",
      " '        metrics = {k: metrics[k] for k in serializable_metrics}\\n'\n",
      " '        logger.info(\\n'\n",
      " '            f\"report_validation_metrics(steps_completed={steps_completed} '\n",
      " 'metrics={metrics})\"\\n'\n",
      " '        )\\n'\n",
      " '\\n'\n",
      " 'From file determined/proto/src/determined/api/v1/api.proto (github url '\n",
      " 'https://github.com/determined-ai/determined/blob/main/proto/src/determined/api/v1/api.proto):\\n'\n",
      " 'body: \"validation_metrics\"\\n'\n",
      " '    };\\n'\n",
      " '    option (grpc.gateway.protoc_gen_swagger.options.openapiv2_operation) = '\n",
      " '{\\n'\n",
      " '      tags: \"Internal\"\\n'\n",
      " '    };\\n'\n",
      " '  }\\n'\n",
      " '  // Record a checkpoint.\\n'\n",
      " '  rpc ReportCheckpoint(ReportCheckpointRequest)\\n'\n",
      " '      returns (ReportCheckpointResponse) {\\n'\n",
      " '    option (google.api.http) = {\\n'\n",
      " '      post: \"/api/v1/checkpoints\"\\n'\n",
      " '      body: \"checkpoint\"\\n'\n",
      " '    };\\n'\n",
      " '    option (grpc.gateway.protoc_gen_swagger.options.openapiv2_operation) = '\n",
      " '{\\n'\n",
      " '      tags: \"Internal\"\\n'\n",
      " '    };\\n'\n",
      " '  }')\n"
     ]
    }
   ],
   "source": [
    "context = get_context_from_query(query)\n",
    "pprint(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85721363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt_with_context(context: str) -> str:\n",
    "    system_prompt_template = \"\"\"Given the following context and code, answer the following question about the Determined AI Github Repo (url: http://www.github.com/determined-ai/determined/). Do not use outside context, and do not assume the user can see the provided context. Try to be as detailed as possible and reference the components that you are looking at. Keep in mind that these are only code snippets, and more snippets may be added during the conversation.\n",
    "        Do not generate code, only reference the exact code snippets that you have been provided with. If you are going to write code, make sure to specify the language of the code and write the result in markdown. For example, if you were writing Python, you would write the following:\n",
    "\n",
    "        ```python\n",
    "        <python code goes here>\n",
    "        ```\n",
    "        \n",
    "        Now, here is the relevant context: \n",
    "\n",
    "        Context: {context}\n",
    "        \"\"\"\n",
    "    return system_prompt_template.format(context=context)\n",
    "\n",
    "\n",
    "def get_context_from_prompt(prompt: str, k: int = 2) -> str:\n",
    "    docs = DB.similarity_search(prompt, k)\n",
    "\n",
    "    context = \"\\n\\n\".join(\n",
    "        [\n",
    "            f'From file {d.metadata[\"source\"]} (github url {d.metadata[\"url\"]}):\\n'\n",
    "            + str(d.page_content)\n",
    "            for d in docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6044f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Given the following context and code, answer the following question about '\n",
      " 'the Determined AI Github Repo (url: '\n",
      " 'http://www.github.com/determined-ai/determined/). Do not use outside '\n",
      " 'context, and do not assume the user can see the provided context. Try to be '\n",
      " 'as detailed as possible and reference the components that you are looking '\n",
      " 'at. Keep in mind that these are only code snippets, and more snippets may be '\n",
      " 'added during the conversation.\\n'\n",
      " '        Do not generate code, only reference the exact code snippets that '\n",
      " 'you have been provided with. If you are going to write code, make sure to '\n",
      " 'specify the language of the code and write the result in markdown. For '\n",
      " 'example, if you were writing Python, you would write the following:\\n'\n",
      " '\\n'\n",
      " '        ```python\\n'\n",
      " '        <python code goes here>\\n'\n",
      " '        ```\\n'\n",
      " '        \\n'\n",
      " '        Now, here is the relevant context: \\n'\n",
      " '\\n'\n",
      " '        Context: From file '\n",
      " 'determined/docs/training/apis-howto/api-core-ug.rst (github url '\n",
      " 'https://github.com/determined-ai/determined/blob/main/docs/training/apis-howto/api-core-ug.rst):\\n'\n",
      " '.. literalinclude:: ../../../examples/tutorials/core_api/1_metrics.py\\n'\n",
      " '      :language: python\\n'\n",
      " '      :pyobject: main\\n'\n",
      " '\\n'\n",
      " '   The ``report_validation_metrics()`` call typically happens after the '\n",
      " 'validation step, however,\\n'\n",
      " '   actual validation is not demonstrated by this example.\\n'\n",
      " '\\n'\n",
      " '#. Create a ``1_metrics.yaml`` file with an ``entrypoint`` invoking the new '\n",
      " '``1_metrics.py`` file.\\n'\n",
      " '   You can copy the ``0_start.yaml`` configuration file and change the first '\n",
      " 'couple of lines:\\n'\n",
      " '\\n'\n",
      " '   .. literalinclude:: ../../../examples/tutorials/core_api/1_metrics.yaml\\n'\n",
      " '      :language: yaml\\n'\n",
      " '      :lines: 1-2\\n'\n",
      " '\\n'\n",
      " '#. Run the code using the command:\\n'\n",
      " '\\n'\n",
      " '   .. code:: bash\\n'\n",
      " '\\n'\n",
      " '      det e create 1_metrics.yaml . -f\\n'\n",
      " '\\n'\n",
      " '#. You can now navigate to the new experiment in the WebUI and view the plot '\n",
      " 'populated with the\\n'\n",
      " '   training and validation metrics.\\n'\n",
      " '\\n'\n",
      " 'From file determined/harness/determined/pytorch/_pytorch_trial.py (github '\n",
      " 'url '\n",
      " 'https://github.com/determined-ai/determined/blob/main/harness/determined/pytorch/_pytorch_trial.py):\\n'\n",
      " '# Report metrics.\\n'\n",
      " '        if self.is_chief:\\n'\n",
      " '            # Skip reporting timings if evaluate_full_dataset() was '\n",
      " 'defined.  This is far less\\n'\n",
      " \"            # common than evaluate_batch() and we can't know how the user \"\n",
      " 'processed their\\n'\n",
      " '            # validation data.\\n'\n",
      " '            if self._evaluate_batch_defined():\\n'\n",
      " '                step_duration = time.time() - step_start_time\\n'\n",
      " '                logging.info(\\n'\n",
      " '                    det.util.make_timing_log(\"validated\", step_duration, '\n",
      " 'num_inputs, num_batches)\\n'\n",
      " '                )\\n'\n",
      " '            det.pytorch._log_tb_metrics(\\n'\n",
      " '                self.context.get_tensorboard_writer(), \"val\", '\n",
      " 'self.state.batches_trained, metrics\\n'\n",
      " '            )\\n'\n",
      " '\\n'\n",
      " '            # Get best validation before reporting metrics.\\n'\n",
      " '            best_validation_before = '\n",
      " 'self.core_context.train.get_experiment_best_validation()\\n'\n",
      " '\\n'\n",
      " '            '\n",
      " 'self.core_context.train.report_validation_metrics(self.state.batches_trained, '\n",
      " 'metrics)\\n'\n",
      " '\\n'\n",
      " '        searcher_metric = None\\n'\n",
      " '\\n'\n",
      " 'From file determined/harness/determined/pytorch/_reducer.py (github url '\n",
      " 'https://github.com/determined-ai/determined/blob/main/harness/determined/pytorch/_reducer.py):\\n'\n",
      " 'return metrics\\n'\n",
      " '\\n'\n",
      " 'From file determined/harness/determined/core/_train.py (github url '\n",
      " 'https://github.com/determined-ai/determined/blob/main/harness/determined/core/_train.py):\\n'\n",
      " 'def report_training_metrics(\\n'\n",
      " '        self,\\n'\n",
      " '        steps_completed: int,\\n'\n",
      " '        metrics: Dict[str, Any],\\n'\n",
      " '        batch_metrics: Optional[List[Dict[str, Any]]] = None,\\n'\n",
      " '    ) -> None:\\n'\n",
      " '        logger.info(\\n'\n",
      " '            f\"report_training_metrics(steps_completed={steps_completed}, '\n",
      " 'metrics={metrics})\"\\n'\n",
      " '        )\\n'\n",
      " '        logger.debug(\\n'\n",
      " '            f\"report_training_metrics(steps_completed={steps_completed},\"\\n'\n",
      " '            f\" batch_metrics={batch_metrics})\"\\n'\n",
      " '        )\\n'\n",
      " '\\n'\n",
      " '    def report_validation_metrics(self, steps_completed: int, metrics: '\n",
      " 'Dict[str, Any]) -> None:\\n'\n",
      " '        serializable_metrics = self._get_serializable_metrics(metrics)\\n'\n",
      " '        metrics = {k: metrics[k] for k in serializable_metrics}\\n'\n",
      " '        logger.info(\\n'\n",
      " '            f\"report_validation_metrics(steps_completed={steps_completed} '\n",
      " 'metrics={metrics})\"\\n'\n",
      " '        )\\n'\n",
      " '\\n'\n",
      " 'From file determined/proto/src/determined/api/v1/api.proto (github url '\n",
      " 'https://github.com/determined-ai/determined/blob/main/proto/src/determined/api/v1/api.proto):\\n'\n",
      " 'body: \"validation_metrics\"\\n'\n",
      " '    };\\n'\n",
      " '    option (grpc.gateway.protoc_gen_swagger.options.openapiv2_operation) = '\n",
      " '{\\n'\n",
      " '      tags: \"Internal\"\\n'\n",
      " '    };\\n'\n",
      " '  }\\n'\n",
      " '  // Record a checkpoint.\\n'\n",
      " '  rpc ReportCheckpoint(ReportCheckpointRequest)\\n'\n",
      " '      returns (ReportCheckpointResponse) {\\n'\n",
      " '    option (google.api.http) = {\\n'\n",
      " '      post: \"/api/v1/checkpoints\"\\n'\n",
      " '      body: \"checkpoint\"\\n'\n",
      " '    };\\n'\n",
      " '    option (grpc.gateway.protoc_gen_swagger.options.openapiv2_operation) = '\n",
      " '{\\n'\n",
      " '      tags: \"Internal\"\\n'\n",
      " '    };\\n'\n",
      " '  }\\n'\n",
      " '        ')\n"
     ]
    }
   ],
   "source": [
    "system_prompt = get_system_prompt_with_context(context)\n",
    "pprint(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4902033c",
   "metadata": {},
   "source": [
    "# Getting Answers, Finally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149b4dea",
   "metadata": {},
   "source": [
    "Different forms of messages: `SystemMessage`, `HumanMessage` and `AIMessage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fead4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_prompt = [SystemMessage(content=system_prompt), HumanMessage(content=query)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c29ed260",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "            model_name=MODEL,\n",
    "            temperature=0.7,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(full_prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238bd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d0ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
